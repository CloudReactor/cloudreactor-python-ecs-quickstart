project_name: "cloudreactor-python-ecs-quickstart"
project_version_text: 1.1.0
# Optionally, provide a steadily increasing whole number to indicate which
# build is more updated than another.
# project_version_number: 100100000
project_url: "https://github.com/CloudReactor/cloudreactor-python-ecs-quickstart"

default_build_options:
  # dockerfile_path: "{{ docker_context_dir }}/Dockerfile"

  # Options passed after "docker" to all docker commands
  # docker_common_general_options: ""

  # Options passed after "docker" and "build"
  # docker_build_general_options: "--debug"

  # Additional options passed after "docker build"
  extra_docker_build_args: ""

  # # Options passed between "docker" and "tag"
  # docker_tag_general_options: ""

  # # Additional options passed after "docker tag"
  # extra_docker_tag_args: ""

  # # Options passed between "docker" and "push"
  # docker_push_general_options: ""

  # # Additional options passed after "docker push"
  # extra_docker_push_args: ""

default_cloudreactor:
  # # Base URL of API server. Can be overridden if you're running your own
  # # instance of the CloudReactor Task Manager.
  # api_base_url: https://api.cloudreactor.io

  # # Set to false to disable monitoring and management in CloudReactor.
  enabled: true

# These settings will apply by default to all tasks and in all deployments.
# They override the settings in your Run Environment.
# To manage a setting in the CloudReactor UI, omit the property name and value.
# To clear a property name and value, using the default value in the
# Run Environment, set the property value to null.
# See https://apidocs.cloudreactor.io/#operation/tasks_create for a list of all
# properties.
# These properties can also be applied to task_name_to_config[task_name] and
# default_env_task_config[task_name], which will override those set here.
default_task_config:
  command: "python src/task_1.py"

  # # Set to false to skip this Task's deployment. This is usually set per-Task
  # # in task_name_to_config[task_name].deployed
  # deployed: "{{ env == 'staging' }}"

  # # Set to false to disable the Tasks's schedule/service in CloudReactor.
  # # Usually you should leave this unset and manage the setting in the
  # # CloudReactor dashboard. This is usually set per-Task in
  # # task_name_to_config[task_name].enabled
  # enabled: true

  # # To execute the Task on a schedule, a cron or rate expression can be used.
  # # Expression syntax is documented here:
  # # https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html
  # # This is usually set per-Task in task_name_to_config[task_name].schedule
  # schedule: cron(0 12 * * ? *)

  # # The number of Task Executions to create at the scheduled time.
  # scheduled_instance_count: 1

  # # The number of Task Executions to keep running continuously. Setting this
  # # to 1 or greater makes the Task a service. Setting this to null or 0 makes
  # # the Task a non-service.
  # service_instance_count: 1

  # # Maximum number of concurrent Task Executions of the same Task.
  # # CloudReactor will block attempts to start Task Executions when the
  # # existing number of running Task Executions reaches this limit.
  # # -1 means no limit.
  # max_concurrency: 1

  # min_service_instance_count

  # max_age_seconds: 7200

  # # The number of seconds after which a Task is manually started, but
  # # before the Task actually reports it started, before an alert is
  # # triggered.
  # max_manual_start_delay_before_alert_seconds: 60

  # max_manual_start_delay_before_abandonment_seconds:

  # # Tolerance for late heartbearts, in seconds, before a missing heartbeat
  # # alert is triggered.
  # max_heartbeat_lateness_before_alert_seconds: 120

  # max_heartbeat_lateness_before_abandonment_seconds: 0
  # postponed_failure_before_success_seconds: 0
  # max_postponed_failure_count: 0
  # max_postponed_timeout_count: 0
  # postponed_missing_execution_before_start_seconds: 0
  # max_postponed_missing_execution_count: 0
  # min_missing_execution_delay_seconds: 0
  # should_clear_failure_alerts_on_success: true
  # should_clear_timeout_alerts_on_success: true
  # is_scheduling_managed: true
  # is_service_managed: true
  # default_input_value: null
  # input_value_schema: null
  # output_value_schema: null
  # managed_probability: 1.0
  # failure_report_probability: 1.0
  # timeout_report_probability: 1.0

  # # Environment variables to set in the process environment
  env:
    DEPLOYMENT: "{{env}}"

  # alert_methods:
  #   - Alert Method 1
  # links:
  #  - name: Rollbar
  #    link_url_template: "https://rollbar.com/YourCompanyName/YourProject/"
  #    icon_url: "https://cdn.rollbar.com/static/img/favicon.ico"
  #  - name: SumoLogic
  #    # We have to do some tricks because this file is parsed as Jinja2, then re-parsed on upload.
  #    link_url_template: "https://service.us2.sumologic.com/ui/index.html#section/search/@{% raw %}{{ '{{' }}(current_timestamp * 1000) - 3600000{{ '}}' }},{{ '{{' }}current_timestamp * 1000{{ '}}' }}{% endraw %}@_sourceHost={{log_query | urlencode}}"
  #    # Unfortunately, this icon does not show up, probably due to some cross-site inclusion limitations.
  #    icon_url: "https://www.sumologic.com/favicon.ico"
  #    description: "{{log_query}}"

  ecs:
    # # See https://aws.amazon.com/fargate/pricing/
    # # for supported combinations.
    cpu_units: 256
    memory_mb: 512
    # # See https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html
    # # for supported platform versions. Can also be set to "LATEST".
    # platform_version: "LATEST"

    # # Required when deploying a scheduled task without CloudReactor
    # execution_role_arn: arn:aws:iam::123456789012:role/ecsEventsRole

    # enable_ecs_managed_tags: true

    task:
      role_arn: "arn:aws:iam::{{ aws.account_id }}:role/{{ project_name }}_task_{{env}}"

      # network:
      #   subnets:
      #     - subnet_1
      #     - subnet_2
      #   security_groups:
      #     - sg_1
      #     - sg_2
      #   assign_public_ip: true
      tags:
        ManagedBy: CloudReactor
        Application: "{{ project_name }}"

    # # By default, the entrypoint is run with the tinit init process so that
    # # commands in shell form (like calling proc_wrapper) pass on SIGTERM to
    # # the underlying commands. This is so AWS ECS can gracefully shutdown a
    # # container, if the command handles the SIGTERM signal.
    # # To enable tinit, we set the containerDefinitions[0].linuxParameters
    # # property to { "initProcessEnabled" true }. However, if you need to set
    # # other linuxParameter properties, you can set
    # # use_default_linux_parameters to false and pass them in via
    # # extra_main_container_properties.
    # use_default_linux_parameters: true

    # # Uncomment to add properties to the main container:
    # extra_main_container_properties
    #   secrets:
    #     - name: environment_variable_name
    #       valueFrom: arn:aws:secretsmanager:[aws_region]:[aws_account_id]:secret:[secret_name]

    # # Uncomment to add properties to the top-level ECS task definition:
    # extra_task_definition_properties:
    #   volumes:
    #     - name: "database_scratch"
    #       host: {}

    # # To add extra containers to the task:
    # # Extra CPU/memory allocated to the extra containers,
    # # will be taken away from the total cpu_units and memory_mb
    # # allocated for the entire task.
    # extra_container_cpu_units: 32
    # extra_container_memory_mb: 128
    # # Each definition has the properties for containers in an AWS ECS task
    # # definition,
    # # The following example uses nginx as a reverse proxy. It assumed that a Docker image
    # # based on nginx, with configuration, is available in ECR already.
    # # See https://medium.com/@stefanofrancavilla/deploy-web-apps-nginx-to-ecs-with-docker-580c6af827e8
    # # except ECS cluster configuration is not needed since we're using Fargate.
    # # additional_container_definitions:
    #  - name: Some Container Name
    #    image: XXXXXXXXXX.dkr.ecr.us-west-2.amazonaws.com/configured-nginx
    #    cpu: 256
    #    memory: 1024
    #    essential: "true"
    #    portMappings:
    #      - containerPort: 80 # nginx default port is 80
    #      - hostPort: 8000    # port of the target group
    #      - protocol: tcp

  # Properties sent to the wrapper, normally CloudReactor python proc_wrapper.
  # See https://github.com/CloudReactor/cloudreactor-procwrapper
  wrapper:
    # # Working directory to execute command in
    # work_dir: .

    # # The shell mode determines whether or not the process command is
    # # executed in the shell. Options:
    # # auto: Try to auto-detect from the command (the default mode)
    # # enable: Force the shell to be used
    # # disable: Force the shell not to be used
    # shell_mode: auto

    # # Normally proc_wrapper strips extra wrapping of process commands with
    # # shell invocations. For example, it changes the command-line
    # # "/bin/sh -c 'java -jar app.jar'" to
    # # "java -jar app.jar" and uses the shell to execute the command.
    # # Extra wrapping can be introduced by Docker when using shell
    # # form of ENTRYPOINT and CMD.
    # # Set the "strip_shell_wrapping" parameter to false to disable the
    # # stripping.
    # strip_shell_wrapping: true

    # Maximum number of times to retry failed processes.
    # -1 means to retry forever.
    process_max_retries: 1

    # # Number of seconds to wait before retrying a process.
    # process_retry_delay_seconds: 60

    # Timeout for process, in seconds. -1 means no timeout.
    # process_timeout_seconds: -1

    # # Number of seconds to wait between checking the status of processes.
    # process_check_interval: 10

    # # Number of seconds to wait after sending SIGTERM to a process, but
    # # before killing it with SIGKILL.
    # process_termination_grace_period: 30

    # # Send termination and kill signals to the process group of the wrapped
    # # process only, instead of only the wrapped process. Sending to the
    # # process group allows all child processes to receive the signals, even if
    # # the wrapped process does not forward signals. This is especially
    # # important when running wrapped processes in a shell.
    # process_group_termination: true

    # # Top-level .env secret locations. The values in later locations take
    # # precedence over those in earlier locations.
    env_locations:
      - "arn:aws:secretsmanager:{{ aws_region }}:{{ aws.account_id }}:secret:{{ project_name | replace('-', '_') }}/{{env}}/tasks/env"
    #   - arn:aws:s3:::examplebucket/{{env}}/app/config.json
    #   - file:///home/appuser/.env

    # # proc_wrapper can also load a configuration dictionary, merged from
    # # the sources below.
    # config_locations:
    #   - arn:aws:secretsmanager:us-east-2:1234567890:secret:myapp/{{env}}/env
    #   - arn:aws:s3:::examplebucket/{{env}}/app1/config.json

    # # Merge stategy for configuration / environment. Can be one of these:
    # # SHALLOW, REPLACE, ADDITIVE, TYPESAFE_REPLACE, TYPESAFE_ADDITIVE
    # # Strategies other than SHALLOW require merge_deep to be installed.
    # config_merge_strategy: SHALLOW

    # # Normally secrets fetched externally do not overwrite environment
    # # variables that are already set, since they could be set when manually
    # # starting a Task. Change this to false to allow overwriting.
    # overwrite_env_with_secrets: false

    # # Time-To-Live for cached secret values, in seconds. If the process
    # # fails, before it restarts, if the TTL has been exceeded, the secrets
    # # will be re-fetched. The default value is -1 which means values are
    # # cached indefinitely.
    # config_ttl_seconds: -1

    # # Enable/disable secret resolution
    resolve_secrets: true

    # # Secret values may be dictionaries that contain embedded values that
    # # need to be resolved. proc_wrapper resolves embedded secret values
    # # up to a maximum depth, which is 5 by default.
    # max_config_resolution_depth: 5

    # # When a secret value is fetched, it may contain a dictionary that also
    # # has values that need to be resolved. Therefore proc_wrapper makes
    # # multiple passes to try to resolve all secrets. The default maximum
    # # number of passes is 3.
    # max_config_resolution_iterations: 3

    # # Set to true to immediately stop execution if any error happens during
    # # secrets resolution. This is the default behavior. You may set this to
    # # false to debug configuration issues, in which case secret fetching
    # # and resolution won't fail until all possible fetching and resolution
    # # is attempted.
    # fail_fast_config_resolution: true

    # # proc_wrapper looks for environment variable names that begin with a
    # # specific prefix and a specific suffix. Those variables with have
    # # values used to fetch a secret. The secret is given the environment
    # # variable name with the prefix and suffix removed. By default, no
    # # name prefix is necessary, but the name suffix is
    # # "_FOR_PROC_WRAPPER_TO_RESOLVE".
    # resolvable_env_var_name_prefix: ""
    # resolvable_env_var_name_suffix: "_FOR_PROC_WRAPPER_TO_RESOLVE"

    # # proc_wrapper looks for configuration property names that begin with a
    # # specific prefix and a specific suffix. Those variables with have
    # # values used to fetch a secret. The secret is given the property
    # # name with the prefix and suffix removed. By default, no name prefix is
    # # necessary, but the name suffix is "__to_resolve" (with 2 leading
    # # underscores).
    # resolvable_config_property_name_prefix: ""
    # resolvable_config_property_name_suffix: "__to_resolve"

    # # After the configuration dictionary is resolved, proc_wrapper can set
    # # an environment variable to the JSON-encoded configuration dictionary,
    # # if you give the variable a name below. By default, proc_wrapper does not
    # # set the configuration dictionary in the environment.
    # env_var_name_for_config: null

    # # If true, do not start processes if the API server is unavailable or the
    # # wrapper is misconfigured.
    # prevent_offline_execution: false

    # # Send the process ID to CloudReactor for debugging.
    # send_pid: true

    # # Send the hostname to CloudReactor for debugging.
    # send_hostname: true

    # # Send metadata about the runtime environment (such as the ECS Task ARN)
    # # to CloudReactor for debugging and management purposes.
    # send_runtime_metadata: true

    # # Number of seconds to wait between sending heartbeats to CloudReactor.
    # # -1 means to not send heartbeats.
    # api_heartbeat_interval_seconds: 300

    # # Number of seconds to wait while receiving recoverable errors from
    # # CloudReactor.
    # api_error_timeout_seconds: 300

    # # Number of seconds to wait before retrying an API request.
    # api_retry_delay_seconds: 120

    # # Number of seconds to wait before resuming API requests, after retries
    # # are exhausted. -1 means to never resume.
    # api_resume_delay_seconds: 600

    # # Number of seconds to keep retrying Task Execution creation while
    # # receiving error responses from CloudReactor. -1 means to keep trying
    # # indefinitely.
    # api_task_execution_creation_error_timeout_seconds: 300

    # # Number of seconds to keep retrying Task Execution creation while
    # # a conflict is detected. -1 means to keep trying indefinitely.
    # api_task_execution_creation_conflict_timeout_seconds: 300

    # # Number of seconds between attempts to retry Task Execution creation
    # # after a conflict is detected.
    # api_task_execution_creation_conflict_retry_delay_seconds: 120

    # # Number of seconds to wait while receiving recoverable errors from
    # # CloudReactor when sending the final update before exiting.
    # api_final_update_timeout_seconds: 1800

    # # Timeout for contacting the CloudReactor API server, in seconds.
    # api_request_timeout_seconds: 30

    # # Listen for status updates from the process, sent on the status socket
    # # port via UDP.
    enable_status_update_listener: true

    # # Minimum of number of seconds to wait between sending status updates to
    # # the API server. -1 means to not send status updates except with
    # # heartbeats.
    # status_update_interval_seconds: 60

    # # The port used to receive status updates from the process.
    # status_update_socket_port: 2373

    # # Default log level is INFO, set to DEBUG here for initial deployments.
    # # Valid choices are DEBUG, INFO, WARNING, ERROR, and CRITICAL.
    log_level: DEBUG

    # Set to false to exclude timestamps from the log output, in case
    # are timestamps are added by the logging provider. The deployer sets up
    # CloudWatch Logs (which adds timestamps) for this project, so we
    # set this to false here.
    include_timestamps_in_log: false

    # # Log sensitive information, such as the API key and fetched secrets.
    # log_secrets: true

    # # This data is sent back from the wrapper to CloudReactor when it starts.
    # # It may be used to identify properties about instance of the task that is
    # # running.
    # other_metadata:
    #   a: 'b'
    #   embedded:
    #     c: 'd'
    #     f: 1

    # # Optional Rollbar token used by the wrapper script.
    # # Can point to AWS Secrets Manager, or be the access token itself.
    # rollbar_access_token: "arn:aws:secretsmanager:[aws_region]:[aws_account_id]:secret:CloudReactor/example/common/rollbar_access_token-xxx"

    # # Number of retries per Rollbar request.
    # rollbar_retries: 2

    # # Number of seconds to wait before retrying a Rollbar request.
    # rollbar_retry_delay_seconds: 120

    # # Timeout for contacting Rollbar server, in seconds.
    # rollbar_timeout_seconds: 30

# These are per-task settings that will inherit and override the settings in
# default_task_config, in all environments.
# To add a task, add an additional property to task_name_to_config (e.g. task_1, file_io)
# Each task must at a minimum define which command to run i.e.
# `command: python main.py`

# These are per-Task settings that will inherit and override the settings in
# default_task_config, in all environments.
# To add a Task, add an additional property to task_name_to_config (e.g. task_1, file_io)
# Each Task must at a minimum define which command to run i.e. `command: python main.py`
task_name_to_config:
  # This Task sends status back to CloudReactor as it is running
  task_1:
    description: "This description shows up in CloudReactor dashboard"
    schedule: cron(9 15 * * ? *)
    # scheduled_instance_count: 1
    wrapper:
      enable_status_update_listener: true
  # This task shows how to use the temporary file system provided by ECS
  file_io:
    description: "File I/O"
    command: "python src/file_io.py"
    ecs:
      extra_main_container_properties:
        mountPoints:
          - sourceVolume: "database_scratch"
            containerPath: "/home/appuser/scratch"
      extra_task_definition_properties:
        volumes:
          - name: "database_scratch"
            host: {}
    env:
      TEMP_FILE_DIR: "/home/appuser/scratch"
  secret_access:
    command: "python src/secret_access.py"
  web_server:
    command: "flask run -p 7070 --host=0.0.0.0"
    # Uncomment to enable web server -- requires an IP target group and
    # load balancer setup in AWS
    deployed: false
    description: "Web Server"
    max_concurrency: null
    is_service: true
    service_instance_count: 1
    env:
      FLASK_APP: src/web_server.py
    ecs:
      task:
        network:
          assign_public_ip: true
      service:
        deployment_configuration:
          force_new_deployment: false
          minimum_healthy_percent: 100
          maximum_percent: 200
          enable_circuit_breaker: true
          rollback_on_failure: true
        enable_ecs_managed_tags: true
        propagate_tags: SERVICE # Or "TASK_EXECUTION"
        tags:
          Environment: "{{env}}"
          TaskType: Service
      extra_main_container_properties:
        portMappings:
          - hostPort: 7070
            containerPort: 7070
            protocol: tcp

# env_to_default_task_config is a mapping from deployment environment name to
# non-secret Task settings common to all Tasks.
env_to_default_task_config:
  staging:
    env:
      FEATURE_A_ENABLED: "TRUE"

  production:
    env:
      FEATURE_A_ENABLED: "FALSE"


# env_to_task_name_to_config is a mapping from deployment environment name to
# another mapping from Task name to non-secret Task settings.
env_to_task_name_to_config:
  staging:
    smoke:
      schedule: cron(9 0 * * ? *)

  production:
    smoke:
      schedule: cron(12 0 * * ? *)

# # Uncomment to set non-secret properties web server in production.
#  web_server:
#    deployed: true
#    service_instance_count: 2
#    ecs:
#      execution_role_arn: arn:aws:iam::12345678901:role/myrole
#      task:
#        network:
#         security_groups:
#           - sg-1
#           - sg-2
#         subnets:
#           - subnet-public-1
#           - subnet-public-2
#        role_arn: arn:aws:iam::12345678901:role/myrole
#      service:
#        load_balancers:
#          - target_group_arn: arn:aws:elasticloadbalancing:us-west-1:xxx:targetgroup/example-web/xxx
#            container_port: 7070
#    links:
#      - name: Web Server
#        link_url_template: "http://flask-example-xxx.us-west-1.elb.amazonaws.com/"
#        description: Main web page
